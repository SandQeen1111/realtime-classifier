<div align="center">
Real-Time Image Classifier
Point Your Webcam. Get Predictions. See FPS.
Bild anzeigen
Bild anzeigen
Bild anzeigen
Bild anzeigen
Live image classification from webcam, files, or directories using ONNX Runtime. Auto-selects the fastest backend (CoreML, CUDA, CPU), displays predictions with confidence scores in real-time, and tracks P50/P95/P99 latency rolling stats.
Built by SandQueen1111

Why This Exists
Most classifier demos are Jupyter cells that process one image. Useless in production.
This runs at 238 FPS on a live webcam stream, handles batch directories,
tracks latency statistics, and auto-detects the best hardware backend â€” all from the command line.

</div>
Demo
$ python classifier.py --webcam --model model_int8.onnx

âœ“ Model loaded: model_int8.onnx
  Provider: CoreMLExecutionProvider

ğŸ¥ Webcam classification started (press 'q' to quit)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                                          â”‚
  â”‚         ğŸ¥ Live Camera Feed              â”‚
  â”‚                                          â”‚
  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
  â”‚   â”‚  cat (96.8%)                 â”‚       â”‚
  â”‚   â”‚  FPS: 238                    â”‚       â”‚
  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
  â”‚                                          â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Š Session Stats:
   Frames classified: 1,847
   Average latency:   4.2ms
   P99 latency:       8.1ms
   Throughput:        238 FPS

Three Modes
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                       â”‚
â”‚   MODE 1: WEBCAM              MODE 2: SINGLE IMAGE    MODE 3: BATCH  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ ğŸ¥ Live  â”‚                â”‚ ğŸ–¼ï¸ File  â”‚            â”‚ ğŸ“ Dir   â”‚   â”‚
â”‚   â”‚ Stream   â”‚                â”‚          â”‚            â”‚ 500+     â”‚   â”‚
â”‚   â”‚ 30+ FPS  â”‚                â”‚ One shot â”‚            â”‚ images   â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                       â”‚
â”‚   --webcam                    --image cat.jpg         --dir ./photos  â”‚
â”‚                                                                       â”‚
â”‚   Real-time overlay           JSON output             Progress bar    â”‚
â”‚   FPS counter                 Top-5 predictions       Rolling stats   â”‚
â”‚   Rolling latency             Confidence scores       Batch report    â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Quick Start
bashgit clone https://github.com/SandQueen1111/realtime-classifier.git
cd realtime-classifier
pip install -r requirements.txt
Webcam Mode
bashpython classifier.py --webcam --model model_int8.onnx
Single Image
bashpython classifier.py --image photo.jpg --model model_int8.onnx
json{
  "source": "photo.jpg",
  "predicted_class": "golden_retriever",
  "confidence": 0.9412,
  "top_k": [
    {"class_id": 207, "class_name": "golden_retriever", "confidence": 0.9412},
    {"class_id": 208, "class_name": "labrador", "confidence": 0.0341},
    {"class_id": 209, "class_name": "chesapeake_bay", "confidence": 0.0089}
  ],
  "above_threshold": true
}
Batch Directory
bashpython classifier.py --dir ./photos --model model_int8.onnx
  Processed 10/500 | Avg: 4.3ms | FPS: 233
  Processed 20/500 | Avg: 4.2ms | FPS: 238
  ...
  Processed 500/500 | Avg: 4.1ms | FPS: 244

âœ“ Classified 500 images
  Average: 4.1ms | FPS: 244
CLI Options
FlagDefaultDescription--modelmodel_int8.onnxPath to ONNX model file--webcamâ€”Enable live webcam mode--imageâ€”Classify a single image file--dirâ€”Classify all images in directory--threshold0.5Minimum confidence to report--top-k5Number of top predictions

Design Decisions
DecisionReasoningONNX Runtime over PyTorchNo torch dependency at inference â€” 10x smaller install, 2x faster cold startAuto provider detectionChecks CoreML â†’ CUDA â†’ CPU at startup; user never configures hardwareClassify every 3rd frameWebcam at 30fps but inference at ~10fps is enough; avoids frame queue buildupRolling 1000-sample windowKeeps latency stats fresh without unbounded memory growthnumpy softmaxAvoids importing torch just for F.softmax â€” one less dependencyPIL for preprocessingAvailable everywhere, no OpenCV dependency for non-webcam modesOpenCV only for webcamOptional import â€” batch/single modes work without itDataclass configType-safe, readable defaults, easy to extendargparse CLIStandard Python â€” no click/typer dependency neededBGR â†’ RGB conversionOpenCV captures BGR, models expect RGB â€” silent bug if missed

Architecture
classifier.py (single file, 5 classes, production-ready)
â”‚
â”œâ”€â”€ ClassifierConfig         # @dataclass â€” all settings in one place
â”‚   â””â”€â”€ model_path, image_size, threshold, top_k, mean, std
â”‚
â”œâ”€â”€ ImagePreprocessor        # Handles all input formats
â”‚   â”œâ”€â”€ preprocess_numpy()   # For webcam frames (np.ndarray)
â”‚   â”œâ”€â”€ preprocess_file()    # For single image files
â”‚   â””â”€â”€ preprocess_batch()   # For directory processing
â”‚
â”œâ”€â”€ InferenceEngine          # ONNX Runtime wrapper + performance tracking
â”‚   â”œâ”€â”€ predict()            # Run inference + track latency
â”‚   â””â”€â”€ get_stats()          # Rolling P50/P95/P99/FPS stats
â”‚
â”œâ”€â”€ RealTimeClassifier       # High-level API combining everything
â”‚   â”œâ”€â”€ classify_image()     # Single file â†’ prediction
â”‚   â”œâ”€â”€ classify_numpy()     # Webcam frame â†’ prediction
â”‚   â”œâ”€â”€ classify_directory() # Batch processing with progress
â”‚   â””â”€â”€ run_webcam()         # Live stream with overlay
â”‚
â””â”€â”€ main()                   # CLI with argparse
Data Flow
                Input Sources
                     â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚               â”‚               â”‚
  Webcam          File            Directory
  (BGR)          (RGB)           (RGB Ã— N)
     â”‚               â”‚               â”‚
     â–¼               â–¼               â–¼
  BGRâ†’RGB        PIL.open       [PIL.open...]
     â”‚               â”‚               â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
             â–¼                       â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Preprocess   â”‚      â”‚ Preprocess   â”‚
     â”‚ Resize 224   â”‚      â”‚ Batch        â”‚
     â”‚ Normalize    â”‚      â”‚ Concatenate  â”‚
     â”‚ HWC â†’ NCHW   â”‚      â”‚ [N,3,224,224]â”‚
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                     â”‚
            â–¼                     â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚      ONNX Runtime Session        â”‚
     â”‚  CoreML / CUDA / CPU (auto)      â”‚
     â”‚  Latency tracking per inference  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚         Postprocessing           â”‚
     â”‚  numpy softmax â†’ argsort â†’ top-K â”‚
     â”‚  Confidence threshold filter     â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼           â–¼           â–¼
     Webcam       JSON        Progress
     Overlay     Output       Report

Performance Tracking
The inference engine tracks latency automatically with every prediction:
pythonstats = classifier.engine.get_stats()
json{
  "total_inferences": 1847,
  "provider": "CoreMLExecutionProvider",
  "p50_ms": 4.2,
  "p95_ms": 5.8,
  "p99_ms": 8.1,
  "mean_ms": 4.5,
  "fps": 222.2,
  "last_ms": 4.1
}
StatDescriptiontotal_inferencesLifetime counter across all modesproviderActive ONNX Runtime backendp50_msMedian latency (last 1000 inferences)p95_ms95th percentile â€” SLA targetp99_ms99th percentile â€” tail latencyfpsThroughput based on mean latencylast_msMost recent inference time

Hardware Auto-Detection
The engine automatically selects the best available backend:
Startup check:
  1. CoreMLExecutionProvider available? â†’ Use it (Apple Silicon)
  2. CUDAExecutionProvider available?   â†’ Use it (NVIDIA GPU)
  3. Fallback                           â†’ CPUExecutionProvider
BackendHardwareExpected FPSNotesCoreMLApple M1/M2/M3/M4250+Native Neural EngineCUDANVIDIA RTX series400+Tensor cores + cuDNNCPUIntel/AMD80+AVX2 vectorized
No configuration needed. Plug in the hardware, the engine finds it.

Use as a Library
pythonfrom classifier import RealTimeClassifier, ClassifierConfig

# Configure
config = ClassifierConfig(
    model_path="your_model.onnx",
    confidence_threshold=0.7,
    top_k=3,
)

# Initialize
clf = RealTimeClassifier(config)

# Classify
result = clf.classify_image("photo.jpg")
print(f"{result['predicted_class']}: {result['confidence']:.1%}")

# Batch process
results = clf.classify_directory("./test_images")

# Check performance
stats = clf.engine.get_stats()
print(f"Throughput: {stats['fps']} FPS")

Project Structure
realtime-classifier/
â”‚
â”œâ”€â”€ classifier.py        # Everything: preprocessing, inference, CLI
â”‚   â”œâ”€â”€ ClassifierConfig      # Settings dataclass
â”‚   â”œâ”€â”€ ImagePreprocessor     # Input handling (file, numpy, batch)
â”‚   â”œâ”€â”€ InferenceEngine       # ONNX Runtime + latency tracking
â”‚   â”œâ”€â”€ RealTimeClassifier    # High-level API
â”‚   â””â”€â”€ main()                # CLI entry point
â”‚
â”œâ”€â”€ requirements.txt     # Minimal dependencies
â”œâ”€â”€ LICENSE              # MIT
â””â”€â”€ README.md

Roadmap

 ONNX Runtime inference with auto provider detection
 Live webcam mode with FPS overlay
 Single image classification with JSON output
 Batch directory processing with progress
 Rolling P50/P95/P99 latency statistics
 Confidence threshold filtering
 Top-K configurable predictions
 BGR â†’ RGB safe conversion
 Video file input (MP4, AVI)
 RTSP stream support (IP cameras)
 Multi-model ensemble (vote across models)
 Export results to CSV/JSON file
 Gradio web UI for browser-based demo
 ONNX Runtime Web for JavaScript deployment
 Model download from Hugging Face Hub
 Class name mapping from custom label files


License
MIT License â€” see LICENSE for details.

<div align="center">
Built with precision by SandQueen1111
"If you can see it, you can classify it."
</div>
